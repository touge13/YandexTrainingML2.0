{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "qxj6Ivw8KRxL"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import json\n",
        "import itertools\n",
        "import string\n",
        "from collections import Counter\n",
        "from itertools import chain\n",
        "\n",
        "import gensim\n",
        "import numpy as np\n",
        "from nltk.tokenize import WordPunctTokenizer\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 304
        },
        "id": "A4TCJTIxKRxO",
        "outputId": "b3b43994-317c-41a1-ae51-8523c9b5a3ab"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-10-30 06:53:07--  https://www.dropbox.com/s/obaitrix9jyu84r/quora.txt?dl=1\n",
            "Resolving www.dropbox.com (www.dropbox.com)... 162.125.6.18, 2620:100:601c:18::a27d:612\n",
            "Connecting to www.dropbox.com (www.dropbox.com)|162.125.6.18|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://www.dropbox.com/scl/fi/p0t2dw6oqs6oxpd6zz534/quora.txt?rlkey=bjupppwua4zmd4elz8octecy9&dl=1 [following]\n",
            "--2024-10-30 06:53:07--  https://www.dropbox.com/scl/fi/p0t2dw6oqs6oxpd6zz534/quora.txt?rlkey=bjupppwua4zmd4elz8octecy9&dl=1\n",
            "Reusing existing connection to www.dropbox.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘./quora.txt’\n",
            "\n",
            "./quora.txt             [  <=>               ] 164.90K   353KB/s    in 0.5s    \n",
            "\n",
            "2024-10-30 06:53:08 (353 KB/s) - ‘./quora.txt’ saved [168859]\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'    });\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "\n",
        "# Скачиваем данные\n",
        "!wget https://www.dropbox.com/s/obaitrix9jyu84r/quora.txt?dl=1 -O ./quora.txt -nc\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = list(open(\"./quora.txt\", encoding=\"utf-8\"))\n",
        "data[50]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "YpNWabjWNaTT",
        "outputId": "6a7036a2-97b3-4832-9644-88bfac233853"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"What TV shows or books help you read people's body language?\\n\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "Ni0u6bP1KRxP"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Токенизация текста\n",
        "tokenizer = WordPunctTokenizer()\n",
        "data_tok = [\n",
        "    tokenizer.tokenize(\n",
        "        line.translate(str.maketrans(\"\", \"\", string.punctuation)).lower()\n",
        "    )\n",
        "    for line in data\n",
        "]\n",
        "data_tok = [x for x in data_tok if len(x) >= 3]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "8GwUUstGKRxQ"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Убираем редкие слова\n",
        "min_count = 5\n",
        "vocabulary_with_counter = Counter(chain.from_iterable(data_tok))\n",
        "word_count_dict = {word: count for word, count in vocabulary_with_counter.items() if count >= min_count}\n",
        "vocabulary = set(word_count_dict.keys())\n",
        "data_tok = [[word for word in text if word in vocabulary] for text in data_tok]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "4oCZQbpjKRxR"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Обучение модели Word2Vec\n",
        "model = gensim.models.Word2Vec(\n",
        "    sentences=data_tok,\n",
        "    vector_size=32,\n",
        "    window=5,\n",
        "    min_count=5,\n",
        "    sg=1,\n",
        "    negative=15\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "60ahxQGaKRxS",
        "outputId": "efddfb9e-2279-4c4e-a5b6-34ed8e6543c5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Similarity between 'computer' and 'laptop': 0.6427711844444275\n",
            "Similarity between 'computer' and 'desk': 0.5514743328094482\n"
          ]
        }
      ],
      "source": [
        "# Пример с другими словами\n",
        "similarity_computer_laptop = model.wv.similarity(\"computer\", \"laptop\")\n",
        "similarity_computer_desk = model.wv.similarity(\"computer\", \"desk\")\n",
        "print(f\"Similarity between 'computer' and 'laptop': {similarity_computer_laptop}\")\n",
        "print(f\"Similarity between 'computer' and 'desk': {similarity_computer_desk}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Чтение слов из words_subset.txt\n",
        "assert os.path.exists(\"words_subset.txt\"), \"Please, download `words_subset.txt` and place it in the working directory\"\n",
        "with open(\"words_subset.txt\") as iofile:\n",
        "    selected_words = iofile.read().split(\"\\n\")\n",
        "\n",
        "# Генерация эмбеддингов для `submission_dict.json`\n",
        "def get_matrix_for_selected_words(selected_words, model):\n",
        "    word_vectors = []\n",
        "    for word in selected_words:\n",
        "        if word in model.wv:\n",
        "            vector = model.wv[word].tolist()\n",
        "        else:\n",
        "            vector = [0.0] * model.vector_size\n",
        "        word_vectors.append(vector)\n",
        "    return word_vectors\n",
        "\n",
        "word_vectors = get_matrix_for_selected_words(selected_words, model)\n",
        "\n",
        "# Сохранение вектора слов в файл JSON\n",
        "with open(\"submission_dict.json\", \"w\") as iofile:\n",
        "    json.dump(word_vectors, iofile)\n",
        "print(\"File saved to `submission_dict.json`\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rOKVND30LZ4_",
        "outputId": "d3cd9566-cfec-4520-c0a2-f4d6253d508d"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "File saved to `submission_dict.json`\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.12.2"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}