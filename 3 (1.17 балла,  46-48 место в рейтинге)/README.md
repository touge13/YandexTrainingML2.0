Задание:
В 2084 году человечество установило первый контакт с внеземной цивилизацией, обитающей на планете Зета в созвездии Андромеды. Инопланетяне, которых назвали зетанами, обладают высокоразвитой технологией и стремятся к обмену знаниями с землянами. Для успешного установления контакта и развития взаимовыгодных отношений, чрезвычайно важно наладить эффективную коммуникацию.
Зетаны предоставили человечеству обширную текстовую библиотеку на своем языке, включающую как оригинальные произведения, так и переводы известных земных текстов. В свою очередь, они получили доступ к библиотекам Земли. Однако алгоритмы машинного перевода пока плохо справляются с необычным строением языка зетан, что делает перевод неточным и неполным.
Необходимо обучить модель перевода с языка зетан на английский.
Данные: https://disk.yandex.ru/d/u8mmcUBn64p_Nw
Формат решения: json-lines в формате, аналогичной валидации, с переводами исходных текстов в тестовой выборке
Метрика качества: BLEU между переводами и английскими референсами на закрытом тесте

Задача решалась следующим образом:
1. Чистка обучающей выборки (из 300к примеров получится 235к)
2. BPE токенизатор
3. Архитектура трансформер

По итогу Transformer-base-relpos; filtered пайплайн дает 21.5 метрики BLEU

Моя проблема заключалась в следющем:
1. Я почему-то искренне был уверен, что датасет хороший и чистый
2. Я обучал нейросети максимум на 10к примеров из-за ограничений в вычислительных мощностях (10к примеров обучались 5+ часов)
3. Отсутствие опыта в тонкой настройке обучения нейросети отнимало много времени и давало низкое качество, но, спустя какое-то время стал появляться результат, но все равно есть куда расти, спасибо тренировкам за бесценный опыт!
